{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j6yJsCGeaq8G"
   },
   "outputs": [],
   "source": [
    "!pip install litellm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u129iWNPaf72"
   },
   "outputs": [],
   "source": [
    "import litellm\n",
    "from litellm import embedding, completion\n",
    "\n",
    "model_fallback_list = [\"claude-instant-1\", \"gpt-3.5-turbo\", \"chatgpt-test\"]\n",
    "\n",
    "user_message = \"Hello, how are you?\"\n",
    "messages = [{ \"content\": user_message,\"role\": \"user\"}]\n",
    "\n",
    "for model in model_fallback_list:\n",
    "  try:\n",
    "      response = completion(model=model, messages=messages)\n",
    "  except Exception as e:\n",
    "      print(f\"error occurred: {traceback.format_exc()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-AT1QpiZCUvV6uxUwjVFi9uAnUUFIT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=\"In whispers soft, the shadows play,  \\nAs twilight wraps the world in gray.  \\nThe stars emerge, a silver thread,  \\nIn night's embrace, all fears are shed.  \\n\\nThe moonlight dances on the stream,  \\nA gentle touch, a fleeting dream.  \\nWith every breath, the silence sings,  \\nOf whispered hopes and fragile things.\", refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1731480379, model='gpt-4o-mini', object='chat.completion', service_tier=None, system_fingerprint='fp_d54531d9eb', usage=CompletionUsage(completion_tokens=71, prompt_tokens=17, total_tokens=88, completion_tokens_details=None, prompt_tokens_details=None), prompt_filter_results=[{'prompt_index': 0, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}}])\n"
     ]
    }
   ],
   "source": [
    "import openai # openai v1.0.0+\n",
    "client = openai.OpenAI(api_key=\"sk-1234\",base_url=\"http://0.0.0.0:4000\") # set proxy to base_url\n",
    "# request sent to model set on litellm proxy, `litellm --model`\n",
    "response = client.chat.completions.create(model=\"gpt-4o-mini-2\", messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"this is a test request, write a short poem\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletion' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmessage\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletion' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "response['message']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
